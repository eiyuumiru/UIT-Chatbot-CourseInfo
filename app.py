import streamlit as st
from pathlib import Path
import os
import subprocess

st.set_page_config(page_title="Chatbot m√¥n h·ªçc UIT", page_icon="ü§ñ")

DEVICE = "cuda"
DEFAULT_TOP_K     = 10
DEFAULT_CHUNK_SZ  = 150
DEFAULT_CHUNK_OL  = 20
STORAGE_DIR = Path("storage")
API_KEY     = os.environ.get("GEMINI_API_KEY") or st.secrets.get("GEMINI_API_KEY")

st.sidebar.title("C√†i ƒë·∫∑t RAG")
top_k = st.sidebar.number_input("Max k·∫øt qu·∫£ (top_k)", min_value=1, max_value=50, value=DEFAULT_TOP_K)
device = st.sidebar.selectbox("Device", ["auto", "cuda", "cpu"], index=0)

hybrid = st.sidebar.checkbox("B·∫≠t hybrid search", value=False)
chunk_size    = st.sidebar.slider("Chunk size (keyword)", 50, 500, DEFAULT_CHUNK_SZ, 10)
chunk_overlap = st.sidebar.slider("Chunk overlap", 0, 200, DEFAULT_CHUNK_OL, 5)

st.title("ü§ñ Chatbot m√¥n h·ªçc UIT")

if "history" not in st.session_state:
    st.session_state.history = []

for role, msg in st.session_state.history:
    st.chat_message(role).markdown(msg)

if prompt := st.chat_input("Nh·∫≠p c√¢u h·ªèi (vd: Cho t√¥i th√¥ng tin v·ªÅ IT003?)"):
    st.session_state.history.append(("user", prompt))
    st.chat_message("user").markdown(prompt)

    cmd = [
        "python", "rag_pipeline.py", "query",
        prompt,
        "--top_k", str(top_k),
        "--device", device,
    ]
    if hybrid:
        cmd += [
            "--hybrid",
            "--chunk_size",    str(chunk_size),
            "--chunk_overlap", str(chunk_overlap),
        ]

    with st.chat_message("assistant"):
        with st.spinner("üîç ƒêang t√¨m c√¢u tr·∫£ l·ªùi‚Ä¶"):
            try:
                result = subprocess.run(cmd, capture_output=True, text=True, check=True)
                answer = result.stdout.strip()
            except subprocess.CalledProcessError as e:
                answer = (
                    "**L·ªói khi truy v·∫•n RAG:**\n"
                    f"```bash\n{e.stderr.strip()}\n```"
                )
        st.markdown(answer)

    # L∆∞u l·ªãch s·ª≠ tr·∫£ l·ªùi
    st.session_state.history.append(("assistant", answer))
