import os

os.environ["TIKTOKEN_CACHE_DIR"] = os.path.expanduser("~/.cache/tiktoken")
os.makedirs(os.environ["TIKTOKEN_CACHE_DIR"], exist_ok=True)

import streamlit as st
from rag_pipeline import init_rag_engine, query_hybrid, DEFAULT_CSV

st.set_page_config(layout="centered", page_title="Chatbot m√¥n h·ªçc UIT", page_icon="ü§ñ")
st.title("ü§ñ Chatbot m√¥n h·ªçc UIT")

@st.cache_resource(show_spinner=False)
def load_engine():
    return init_rag_engine(
        csv=DEFAULT_CSV,
        chunk_size=150,
        chunk_overlap=20,
        top_k=10,
        device="cpu",
    )

engine = load_engine()

if "history" not in st.session_state:
    st.session_state.history = []

for role, msg in st.session_state.history:
    st.chat_message(role).markdown(msg)

if prompt := st.chat_input("Nh·∫≠p c√¢u h·ªèi v·ªÅ UIT (vd. Cho t√¥i th√¥ng tin v·ªÅ m√¥n IT003?)"):
    st.session_state.history.append(("user", prompt))
    st.chat_message("user").markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("ƒêang t√¨m c√¢u tr·∫£ l·ªùi‚Ä¶"):
            answer = query_hybrid(engine, prompt)
            st.markdown(answer)

    st.session_state.history.append(("assistant", answer))
